{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBpxUeuIMVWWMPsZZOHXZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asmit-ayank/UCS420/blob/main/Assignment%209/Assignment_9_UCS420.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports,\n",
        "technology, food, books, etc.).\n",
        "1. Convert text to lowercase and remove punctuaƟon.\n",
        "2. Tokenize the text into words and sentences.\n",
        "3. Remove stopwords (using NLTK's stopwords list).\n",
        "4. Display word frequency distribuƟon (excluding stopwords)."
      ],
      "metadata": {
        "id": "o18sj-0p81Dl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI4gDs_Z8kGN",
        "outputId": "83994f5b-0657-489f-ffed-700a361dc37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the moon gets hit by thousands of asteroids everyday yet despite the damage it still looks enchanting in its natural form imagine one day if we take a jcb up there and start filling all the craters thinking we are repairing it but in this process the moon will only lose its beauty  charm\n"
          ]
        }
      ],
      "source": [
        "#1.1\n",
        "import re\n",
        "\n",
        "text = \"The moon gets hit by thousands of asteroids everyday. Yet, despite the damage it still looks enchanting in its natural form. Imagine one day if we take a JCB up there and start filling all the craters thinking we are repairing it but in this process the moon will only lose its beauty & charm.\"\n",
        "\n",
        "text = text.lower()\n",
        "\n",
        "text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.2\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "words = word_tokenize(text)\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "print(\"Words:\", words)\n",
        "print(\"\\nSentences:\", sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgsuwd7z-8ny",
        "outputId": "f73d5d83-69ef-40e1-db6b-32973d006443"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words: ['the', 'moon', 'gets', 'hit', 'by', 'thousands', 'of', 'asteroids', 'everyday', 'yet', 'despite', 'the', 'damage', 'it', 'still', 'looks', 'enchanting', 'in', 'its', 'natural', 'form', 'imagine', 'one', 'day', 'if', 'we', 'take', 'a', 'jcb', 'up', 'there', 'and', 'start', 'filling', 'all', 'the', 'craters', 'thinking', 'we', 'are', 'repairing', 'it', 'but', 'in', 'this', 'process', 'the', 'moon', 'will', 'only', 'lose', 'its', 'beauty', 'charm']\n",
            "\n",
            "Sentences: ['the moon gets hit by thousands of asteroids everyday yet despite the damage it still looks enchanting in its natural form imagine one day if we take a jcb up there and start filling all the craters thinking we are repairing it but in this process the moon will only lose its beauty  charm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.3\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hEsn-R9_q3J",
        "outputId": "0fb6b4f9-d3d1-4300-ffb4-17170ee3eade"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['moon', 'gets', 'hit', 'thousands', 'asteroids', 'everyday', 'yet', 'despite', 'damage', 'still', 'looks', 'enchanting', 'natural', 'form', 'imagine', 'one', 'day', 'take', 'jcb', 'start', 'filling', 'craters', 'thinking', 'repairing', 'process', 'moon', 'lose', 'beauty', 'charm']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.4\n",
        "from collections import Counter\n",
        "\n",
        "word_freq = Counter(filtered_words)\n",
        "\n",
        "print(word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eroQiCpmABFX",
        "outputId": "269fddc6-6506-4b48-f9c3-b7a320001e5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'moon': 2, 'gets': 1, 'hit': 1, 'thousands': 1, 'asteroids': 1, 'everyday': 1, 'yet': 1, 'despite': 1, 'damage': 1, 'still': 1, 'looks': 1, 'enchanting': 1, 'natural': 1, 'form': 1, 'imagine': 1, 'one': 1, 'day': 1, 'take': 1, 'jcb': 1, 'start': 1, 'filling': 1, 'craters': 1, 'thinking': 1, 'repairing': 1, 'process': 1, 'lose': 1, 'beauty': 1, 'charm': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Stemming and LemmaƟzaƟon\n",
        "1. Take the tokenized words from Question 1 (after stopword removal).\n",
        "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
        "3. Apply lemmaƟzaƟon using NLTK's WordNetLemmaƟzer.\n",
        "4. Compare and display results of both techniques."
      ],
      "metadata": {
        "id": "F9J91UGSAT_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2.2\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "\n",
        "porter_stems = [porter.stem(word) for word in filtered_words]\n",
        "lancaster_stems = [lancaster.stem(word) for word in filtered_words]\n",
        "\n",
        "print(\"Porter Stemming:\", porter_stems)\n",
        "print(\"\\nLancaster Stemming:\", lancaster_stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP8LuwfPAXo4",
        "outputId": "65c900a1-0411-4710-d7ad-3fcb78a16fe0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemming: ['moon', 'get', 'hit', 'thousand', 'asteroid', 'everyday', 'yet', 'despit', 'damag', 'still', 'look', 'enchant', 'natur', 'form', 'imagin', 'one', 'day', 'take', 'jcb', 'start', 'fill', 'crater', 'think', 'repair', 'process', 'moon', 'lose', 'beauti', 'charm']\n",
            "\n",
            "Lancaster Stemming: ['moon', 'get', 'hit', 'thousand', 'asteroid', 'everyday', 'yet', 'despit', 'dam', 'stil', 'look', 'ench', 'nat', 'form', 'imagin', 'on', 'day', 'tak', 'jcb', 'start', 'fil', 'crat', 'think', 'repair', 'process', 'moon', 'los', 'beauty', 'charm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.3\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "print(\"Lemmatization:\", lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUu-iW7mBbw_",
        "outputId": "d21f3456-f6f7-4c33-dc12-957b65b8d646"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization: ['moon', 'get', 'hit', 'thousand', 'asteroid', 'everyday', 'yet', 'despite', 'damage', 'still', 'look', 'enchanting', 'natural', 'form', 'imagine', 'one', 'day', 'take', 'jcb', 'start', 'filling', 'crater', 'thinking', 'repairing', 'process', 'moon', 'lose', 'beauty', 'charm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Regular Expressions and Text Spliƫng\n",
        "1. Take their original text from QuesƟon 1.\n",
        "2. Use regular expressions to:\n",
        "a. Extract all words with more than 5 leƩers.\n",
        "b. Extract all numbers (if any exist in their text).\n",
        "c. Extract all capitalized words.\n",
        "3. Use text spliƫng techniques to:\n",
        "a. Split the text into words containing only alphabets (removing digits and special\n",
        "characters).\n",
        "b. Extract words starƟng with a vowel."
      ],
      "metadata": {
        "id": "OBgXpn_tBqKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3.2\n",
        "import re\n",
        "\n",
        "original_text = \"The moon gets hit by thousands of asteroids everyday. Yet, despite the damage it still looks enchanting in its natural form. Imagine one day if we take a JCB up there and start filling all the craters thinking we are repairing it but in this process the moon will only lose its beauty & charm.\"\n",
        "\n",
        "words_more_than_5 = re.findall(r'\\b\\w{6,}\\b', original_text)\n",
        "\n",
        "numbers = re.findall(r'\\b\\d+\\b', original_text)\n",
        "\n",
        "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', original_text)\n",
        "\n",
        "print(\"Words with more than 5 letters:\", words_more_than_5)\n",
        "print(\"Numbers found:\", numbers)\n",
        "print(\"Capitalized words:\", capitalized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbm7aRwRBuCn",
        "outputId": "c6cd34cc-2255-4ec2-abc6-d31baf26fd6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words with more than 5 letters: ['thousands', 'asteroids', 'everyday', 'despite', 'damage', 'enchanting', 'natural', 'Imagine', 'filling', 'craters', 'thinking', 'repairing', 'process', 'beauty']\n",
            "Numbers found: []\n",
            "Capitalized words: ['The', 'Yet', 'Imagine']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.3\n",
        "alpha_words = re.findall(r'\\b[a-zA-Z]+\\b', original_text)\n",
        "\n",
        "vowel_words = [word for word in alpha_words if word.lower()[0] in 'aeiou']\n",
        "\n",
        "print(\"Words containing only alphabets:\", alpha_words)\n",
        "print(\"Words starting with a vowel:\", vowel_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc_qyv_wB68u",
        "outputId": "2d8265de-1d70-48f8-faee-dfef21dde18b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words containing only alphabets: ['The', 'moon', 'gets', 'hit', 'by', 'thousands', 'of', 'asteroids', 'everyday', 'Yet', 'despite', 'the', 'damage', 'it', 'still', 'looks', 'enchanting', 'in', 'its', 'natural', 'form', 'Imagine', 'one', 'day', 'if', 'we', 'take', 'a', 'JCB', 'up', 'there', 'and', 'start', 'filling', 'all', 'the', 'craters', 'thinking', 'we', 'are', 'repairing', 'it', 'but', 'in', 'this', 'process', 'the', 'moon', 'will', 'only', 'lose', 'its', 'beauty', 'charm']\n",
            "Words starting with a vowel: ['of', 'asteroids', 'everyday', 'it', 'enchanting', 'in', 'its', 'Imagine', 'one', 'if', 'a', 'up', 'and', 'all', 'are', 'it', 'in', 'only', 'its']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Custom TokenizaƟon & Regex-based Text Cleaning\n",
        "1. Take original text from QuesƟon 1.\n",
        "2. Write a custom tokenizaƟon funcƟon that:\n",
        "a. Removes punctuaƟon and special symbols, but keeps contracƟons (e.g.,\n",
        "\"isn't\" should not be split into \"is\" and \"n't\").\n",
        "b. Handles hyphenated words as a single token (e.g., \"state-of-the-art\" remains\n",
        "a single token).\n",
        "c. Tokenizes numbers separately but keeps decimal numbers intact (e.g., \"3.14\"\n",
        "should remain as is).\n",
        "\n",
        "3. Use Regex SubsƟtuƟons (re.sub) to:\n",
        "a. Replace email addresses with '<EMAIL>' placeholder.\n",
        "b. Replace URLs with '<URL>' placeholder.\n",
        "c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with\n",
        "'<PHONE>' placeholder."
      ],
      "metadata": {
        "id": "PBbQE4ufCKLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4.2\n",
        "import re\n",
        "\n",
        "original_text = \"The moon gets hit by thousands of asteroids everyday. Yet, despite the damage, it still looks enchanting in its natural form. Imagine one day if we take a JCB up there and start filling all the craters, thinking we are repairing it. But in this process, the moon will only lose its beauty & charm.\"\n",
        "\n",
        "whitespace_tokens = original_text.split()\n",
        "\n",
        "regex_tokens = re.findall(r'\\b\\w+\\b', original_text)\n",
        "\n",
        "print(\"Whitespace Tokenization:\", whitespace_tokens)\n",
        "print(\"\\nRegex Tokenization:\", regex_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFYO73YHCO22",
        "outputId": "dd6752b0-0985-4140-875c-fe32c9cf26d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whitespace Tokenization: ['The', 'moon', 'gets', 'hit', 'by', 'thousands', 'of', 'asteroids', 'everyday.', 'Yet,', 'despite', 'the', 'damage,', 'it', 'still', 'looks', 'enchanting', 'in', 'its', 'natural', 'form.', 'Imagine', 'one', 'day', 'if', 'we', 'take', 'a', 'JCB', 'up', 'there', 'and', 'start', 'filling', 'all', 'the', 'craters,', 'thinking', 'we', 'are', 'repairing', 'it.', 'But', 'in', 'this', 'process,', 'the', 'moon', 'will', 'only', 'lose', 'its', 'beauty', '&', 'charm.']\n",
            "\n",
            "Regex Tokenization: ['The', 'moon', 'gets', 'hit', 'by', 'thousands', 'of', 'asteroids', 'everyday', 'Yet', 'despite', 'the', 'damage', 'it', 'still', 'looks', 'enchanting', 'in', 'its', 'natural', 'form', 'Imagine', 'one', 'day', 'if', 'we', 'take', 'a', 'JCB', 'up', 'there', 'and', 'start', 'filling', 'all', 'the', 'craters', 'thinking', 'we', 'are', 'repairing', 'it', 'But', 'in', 'this', 'process', 'the', 'moon', 'will', 'only', 'lose', 'its', 'beauty', 'charm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.3\n",
        "clean_text = re.sub(r'[^\\w\\s]', '', original_text)\n",
        "\n",
        "clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
        "\n",
        "print(\"Cleaned Text:\", clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GKIYGE8C9Q8",
        "outputId": "fb643658-f920-4ebe-bc56-62b583bd09d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text: The moon gets hit by thousands of asteroids everyday Yet despite the damage it still looks enchanting in its natural form Imagine one day if we take a JCB up there and start filling all the craters thinking we are repairing it But in this process the moon will only lose its beauty charm\n"
          ]
        }
      ]
    }
  ]
}